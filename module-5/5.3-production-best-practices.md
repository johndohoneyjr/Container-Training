# Module 5.3: Production Best Practices

## Progress Software - Container Training Series

---

## Overview

Deploying containerized applications to production requires careful planning for security, high availability, disaster recovery, and operational excellence. This module covers production-grade patterns and practices for running .NET containers in Azure.

---

## Learning Objectives

By the end of this lab, you will be able to:
- Implement high availability and disaster recovery strategies
- Secure containerized applications with Azure Key Vault
- Configure geo-replication for container registries
- Implement backup and restore procedures
- Optimize costs for container workloads
- Apply security hardening checklists
- Design multi-region deployments
- Implement production-grade monitoring and alerting

---

## Prerequisites

- Completed Modules 1-4
- Azure CLI installed and configured
- An active Azure subscription with appropriate permissions
- ACR, AKS, and ACA resources deployed
- Basic understanding of security principles
- Familiarity with Azure Key Vault

---

## Production Readiness Checklist

### Core Requirements

- [ ] **Security**: Secrets management, RBAC, network policies
- [ ] **High Availability**: Multi-replica deployments, health checks
- [ ] **Disaster Recovery**: Backups, geo-replication, runbooks
- [ ] **Monitoring**: Logging, metrics, alerting, tracing
- [ ] **Performance**: Resource limits, autoscaling, optimization
- [ ] **Compliance**: Audit logs, policy enforcement
- [ ] **Cost Optimization**: Resource right-sizing, reserved instances
- [ ] **Documentation**: Architecture diagrams, runbooks, SLAs

---

## Lab 1: Configure Azure Key Vault for Secrets

### Overview
Never store secrets in container images or environment variables directly. Use Azure Key Vault for secure secrets management.

### Step 1: Create and Configure Key Vault

```bash
# Set variables
export RESOURCE_GROUP="rg-containers-production"
export LOCATION="eastus"
export KEY_VAULT_NAME="kv-containers-prod-$RANDOM"
export AKS_CLUSTER="aks-prod-cluster"
export ACR_NAME="acrprod$RANDOM"

# Create resource group
az group create --name $RESOURCE_GROUP --location $LOCATION

# Create Key Vault with RBAC enabled
az keyvault create \
  --name $KEY_VAULT_NAME \
  --resource-group $RESOURCE_GROUP \
  --location $LOCATION \
  --enable-rbac-authorization true \
  --enabled-for-deployment true \
  --enabled-for-template-deployment true

# Get Key Vault resource ID
export KEY_VAULT_ID=$(az keyvault show \
  --name $KEY_VAULT_NAME \
  --resource-group $RESOURCE_GROUP \
  --query id -o tsv)

echo "Key Vault ID: $KEY_VAULT_ID"

# Grant yourself Key Vault Secrets Officer role
export USER_OBJECT_ID=$(az ad signed-in-user show --query id -o tsv)

az role assignment create \
  --role "Key Vault Secrets Officer" \
  --assignee $USER_OBJECT_ID \
  --scope $KEY_VAULT_ID

# Wait for role assignment to propagate
sleep 30
```

### Step 2: Store Secrets in Key Vault

```bash
# Add database connection string
az keyvault secret set \
  --vault-name $KEY_VAULT_NAME \
  --name "DatabaseConnectionString" \
  --value "Server=prod-sql.database.windows.net;Database=proddb;User Id=dbuser;Password=SecureP@ssw0rd123!;Encrypt=true;"

# Add API keys
az keyvault secret set \
  --vault-name $KEY_VAULT_NAME \
  --name "ApiKey-ExternalService" \
  --value "sk-prod-1234567890abcdef"

# Add Application Insights connection string
export APP_INSIGHTS_CONN=$(az monitor app-insights component show \
  --app "appi-prod" \
  --resource-group $RESOURCE_GROUP \
  --query connectionString -o tsv 2>/dev/null || echo "InstrumentationKey=placeholder")

az keyvault secret set \
  --vault-name $KEY_VAULT_NAME \
  --name "ApplicationInsights-ConnectionString" \
  --value "$APP_INSIGHTS_CONN"

# Add Redis connection string
az keyvault secret set \
  --vault-name $KEY_VAULT_NAME \
  --name "Redis-ConnectionString" \
  --value "prod-redis.redis.cache.windows.net:6380,password=RedisP@ssw0rd,ssl=True,abortConnect=False"

# Add Storage account connection string
az keyvault secret set \
  --vault-name $KEY_VAULT_NAME \
  --name "StorageAccount-ConnectionString" \
  --value "DefaultEndpointsProtocol=https;AccountName=prodstorage;AccountKey=storagekey123;EndpointSuffix=core.windows.net"

# List secrets
az keyvault secret list --vault-name $KEY_VAULT_NAME --query "[].{Name:name}" -o table

# Retrieve a secret (for verification)
az keyvault secret show \
  --vault-name $KEY_VAULT_NAME \
  --name "DatabaseConnectionString" \
  --query "value" -o tsv
```

### Step 3: Configure Secret Rotation

```bash
# Enable automatic secret rotation (example for SQL password)
cat > rotation-policy.json <<'EOF'
{
  "lifetimeActions": [
    {
      "trigger": {
        "timeBeforeExpiry": "P30D"
      },
      "action": {
        "type": "Notify"
      }
    }
  ],
  "attributes": {
    "expiryTime": "P90D"
  }
}
EOF

# Set rotation policy
az keyvault secret set-attributes \
  --vault-name $KEY_VAULT_NAME \
  --name "DatabaseConnectionString" \
  --expires "2026-12-31T23:59:59Z"

# Create alert for expiring secrets
az monitor metrics alert create \
  --name "KeyVault-SecretExpiring" \
  --resource-group $RESOURCE_GROUP \
  --scopes $KEY_VAULT_ID \
  --condition "total ServiceApiResult where ApiName == 'SecretGet' and StatusCode == '403'" \
  --description "Alert when secrets are expiring" \
  --evaluation-frequency 5m \
  --window-size 15m
```

### Step 4: Enable Key Vault Audit Logging

```bash
# Create Log Analytics workspace
export LOG_WORKSPACE="law-keyvault-audit"

az monitor log-analytics workspace create \
  --resource-group $RESOURCE_GROUP \
  --workspace-name $LOG_WORKSPACE \
  --location $LOCATION

export WORKSPACE_ID=$(az monitor log-analytics workspace show \
  --resource-group $RESOURCE_GROUP \
  --workspace-name $LOG_WORKSPACE \
  --query id -o tsv)

# Enable diagnostic settings for Key Vault
az monitor diagnostic-settings create \
  --name "KeyVault-Diagnostics" \
  --resource $KEY_VAULT_ID \
  --workspace $WORKSPACE_ID \
  --logs '[{"category": "AuditEvent", "enabled": true}]' \
  --metrics '[{"category": "AllMetrics", "enabled": true}]'

# Query audit logs (after some activity)
echo "After Key Vault usage, query logs with:"
echo "AzureDiagnostics | where ResourceProvider == 'MICROSOFT.KEYVAULT' | where ResultType != 'Success' | project TimeGenerated, OperationName, ResultType, CallerIPAddress, identity_claim_upn_s"
```

---

## Lab 2: Implement Key Vault Integration in Containers

### Overview
Integrate Azure Key Vault with containerized applications using multiple methods.

### Step 1: Use Key Vault with Azure Container Instances (ACI)

```bash
# Create managed identity for ACI
az identity create \
  --name "aci-keyvault-identity" \
  --resource-group $RESOURCE_GROUP

export IDENTITY_ID=$(az identity show \
  --name "aci-keyvault-identity" \
  --resource-group $RESOURCE_GROUP \
  --query id -o tsv)

export IDENTITY_CLIENT_ID=$(az identity show \
  --name "aci-keyvault-identity" \
  --resource-group $RESOURCE_GROUP \
  --query clientId -o tsv)

# Grant identity access to Key Vault
az role assignment create \
  --role "Key Vault Secrets User" \
  --assignee $IDENTITY_CLIENT_ID \
  --scope $KEY_VAULT_ID

# Wait for role assignment
sleep 30

# Deploy ACI with Key Vault reference (volume mount method)
az container create \
  --resource-group $RESOURCE_GROUP \
  --name "aci-with-keyvault" \
  --image mcr.microsoft.com/dotnet/samples:aspnetapp \
  --assign-identity $IDENTITY_ID \
  --ports 80 \
  --cpu 1 \
  --memory 1 \
  --environment-variables \
    "AZURE_CLIENT_ID=$IDENTITY_CLIENT_ID" \
    "KEY_VAULT_NAME=$KEY_VAULT_NAME" \
  --command-line "/bin/bash -c 'apt-get update && apt-get install -y curl && curl -sL https://aka.ms/InstallAzureCLIDeb | bash && dotnet /app/aspnetapp.dll'"

# Verify deployment
az container show \
  --resource-group $RESOURCE_GROUP \
  --name "aci-with-keyvault" \
  --query "{Name:name, State:instanceView.state, IP:ipAddress.ip}"
```

### Step 2: Use Key Vault with AKS - CSI Driver Method (Recommended)

```bash
# Create AKS cluster if not exists
az aks create \
  --resource-group $RESOURCE_GROUP \
  --name $AKS_CLUSTER \
  --node-count 3 \
  --enable-managed-identity \
  --enable-addons azure-keyvault-secrets-provider \
  --generate-ssh-keys

# Get credentials
az aks get-credentials \
  --resource-group $RESOURCE_GROUP \
  --name $AKS_CLUSTER \
  --overwrite-existing

# Verify CSI driver installation
kubectl get pods -n kube-system -l app=secrets-store-csi-driver

# Get AKS identity
export AKS_IDENTITY_CLIENT_ID=$(az aks show \
  --resource-group $RESOURCE_GROUP \
  --name $AKS_CLUSTER \
  --query addonProfiles.azureKeyvaultSecretsProvider.identity.clientId -o tsv)

# Grant AKS access to Key Vault
az role assignment create \
  --role "Key Vault Secrets User" \
  --assignee $AKS_IDENTITY_CLIENT_ID \
  --scope $KEY_VAULT_ID

# Wait for propagation
sleep 30

# Create SecretProviderClass
cat <<EOF | kubectl apply -f -
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: azure-keyvault-secrets
  namespace: default
spec:
  provider: azure
  parameters:
    usePodIdentity: "false"
    useVMManagedIdentity: "true"
    userAssignedIdentityID: "$AKS_IDENTITY_CLIENT_ID"
    keyvaultName: "$KEY_VAULT_NAME"
    cloudName: ""
    objects: |
      array:
        - |
          objectName: DatabaseConnectionString
          objectType: secret
          objectVersion: ""
        - |
          objectName: ApiKey-ExternalService
          objectType: secret
          objectVersion: ""
        - |
          objectName: ApplicationInsights-ConnectionString
          objectType: secret
          objectVersion: ""
    tenantId: "$(az account show --query tenantId -o tsv)"
  secretObjects:
  - secretName: app-secrets
    type: Opaque
    data:
    - objectName: DatabaseConnectionString
      key: db-connection-string
    - objectName: ApiKey-ExternalService
      key: api-key
    - objectName: ApplicationInsights-ConnectionString
      key: appinsights-connection-string
EOF

# Verify SecretProviderClass
kubectl get secretproviderclass azure-keyvault-secrets
```

### Step 3: Deploy Application with Key Vault Secrets

```bash
# Create deployment using Key Vault secrets
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-dotnet-app
  namespace: default
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      containers:
      - name: app
        image: mcr.microsoft.com/dotnet/samples:aspnetapp
        ports:
        - containerPort: 80
        env:
        - name: ConnectionStrings__Database
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: db-connection-string
        - name: ExternalApi__ApiKey
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: api-key
        - name: ApplicationInsights__ConnectionString
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: appinsights-connection-string
        volumeMounts:
        - name: secrets-store
          mountPath: "/mnt/secrets-store"
          readOnly: true
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: secrets-store
        csi:
          driver: secrets-store.csi.k8s.io
          readOnly: true
          volumeAttributes:
            secretProviderClass: "azure-keyvault-secrets"
EOF

# Wait for deployment
kubectl rollout status deployment/secure-dotnet-app

# Verify secrets are mounted
export POD_NAME=$(kubectl get pods -l app=secure-app -o jsonpath='{.items[0].metadata.name}')

kubectl exec -it $POD_NAME -- ls -la /mnt/secrets-store

# Check environment variables (without revealing values)
kubectl exec -it $POD_NAME -- env | grep -E "ConnectionStrings|ExternalApi|ApplicationInsights"

# Verify Kubernetes secret was created
kubectl get secret app-secrets
kubectl describe secret app-secrets
```

### Step 4: .NET Application Code for Key Vault

**Use Azure SDK for direct Key Vault access in application code:**

```csharp
// Install packages:
// dotnet add package Azure.Identity
// dotnet add package Azure.Security.KeyVault.Secrets
// dotnet add package Azure.Extensions.AspNetCore.Configuration.Secrets

using Azure.Identity;
using Azure.Security.KeyVault.Secrets;
using Microsoft.Extensions.Configuration;

public class Program
{
    public static void Main(string[] args)
    {
        var builder = WebApplication.CreateBuilder(args);
        
        // Option 1: Add Key Vault configuration provider
        var keyVaultName = builder.Configuration["KeyVaultName"];
        if (!string.IsNullOrEmpty(keyVaultName))
        {
            var keyVaultUri = new Uri($"https://{keyVaultName}.vault.azure.net/");
            
            // Use DefaultAzureCredential (works with managed identity)
            builder.Configuration.AddAzureKeyVault(
                keyVaultUri,
                new DefaultAzureCredential());
        }
        
        // Option 2: Use Key Vault client directly
        builder.Services.AddSingleton<SecretClient>(sp =>
        {
            var configuration = sp.GetRequiredService<IConfiguration>();
            var keyVaultName = configuration["KeyVaultName"];
            var keyVaultUri = new Uri($"https://{keyVaultName}.vault.azure.net/");
            return new SecretClient(keyVaultUri, new DefaultAzureCredential());
        });
        
        var app = builder.Build();
        
        // Access secrets from configuration
        var dbConnection = app.Configuration["DatabaseConnectionString"];
        var apiKey = app.Configuration["ApiKey-ExternalService"];
        
        app.MapGet("/", () => "Secure app running with Key Vault!");
        
        app.Run();
    }
}
```

**Example service using Key Vault client:**

```csharp
public class SecureConfigurationService
{
    private readonly SecretClient _secretClient;
    private readonly IMemoryCache _cache;
    
    public SecureConfigurationService(SecretClient secretClient, IMemoryCache cache)
    {
        _secretClient = secretClient;
        _cache = cache;
    }
    
    public async Task<string> GetSecretAsync(string secretName)
    {
        // Use caching to reduce Key Vault calls
        var cacheKey = $"secret:{secretName}";
        
        if (!_cache.TryGetValue(cacheKey, out string secretValue))
        {
            KeyVaultSecret secret = await _secretClient.GetSecretAsync(secretName);
            secretValue = secret.Value;
            
            // Cache for 5 minutes
            _cache.Set(cacheKey, secretValue, TimeSpan.FromMinutes(5));
        }
        
        return secretValue;
    }
}
```

---

## Lab 3: Set Up Geo-Replication (ACR Premium)

### Overview
Enable geo-replication for high availability and reduced latency across regions.

### Step 1: Create Premium ACR with Geo-Replication

```bash
# Create Premium tier ACR (required for geo-replication)
az acr create \
  --resource-group $RESOURCE_GROUP \
  --name $ACR_NAME \
  --sku Premium \
  --location $LOCATION

# Enable admin user (for testing only, use managed identity in production)
az acr update --name $ACR_NAME --admin-enabled true

# Get ACR login credentials
export ACR_USERNAME=$(az acr credential show --name $ACR_NAME --query "username" -o tsv)
export ACR_PASSWORD=$(az acr credential show --name $ACR_NAME --query "passwords[0].value" -o tsv)

# Login to ACR
az acr login --name $ACR_NAME

echo "ACR URL: ${ACR_NAME}.azurecr.io"
```

### Step 2: Enable Geo-Replication

```bash
# Add replicas in multiple regions
az acr replication create \
  --registry $ACR_NAME \
  --location westus \
  --resource-group $RESOURCE_GROUP

az acr replication create \
  --registry $ACR_NAME \
  --location westeurope \
  --resource-group $RESOURCE_GROUP

az acr replication create \
  --registry $ACR_NAME \
  --location eastasia \
  --resource-group $RESOURCE_GROUP

# List replications
az acr replication list \
  --registry $ACR_NAME \
  --resource-group $RESOURCE_GROUP \
  --output table

# Expected output:
# Location     Name         ProvisioningState    Status
# -----------  -----------  -------------------  --------
# eastus       eastus       Succeeded            Ready
# westus       westus       Succeeded            Ready
# westeurope   westeurope   Succeeded            Ready
# eastasia     eastasia     Succeeded            Ready
```

### Step 3: Push Images to Geo-Replicated Registry

```bash
# Build and push sample image
cat > Dockerfile.geo <<'EOF'
FROM mcr.microsoft.com/dotnet/aspnet:8.0
WORKDIR /app
COPY . .
ENTRYPOINT ["dotnet", "app.dll"]
EOF

# Create dummy app.dll for testing
echo "Sample content" > app.dll

# Build image
docker build -f Dockerfile.geo -t ${ACR_NAME}.azurecr.io/geo-app:v1.0 .

# Push to ACR (automatically replicated to all regions)
docker push ${ACR_NAME}.azurecr.io/geo-app:v1.0

# Verify image is replicated
az acr repository show \
  --name $ACR_NAME \
  --repository geo-app \
  --query "{Repository:name, Tags:tags}" -o json

# Check replication status
az acr replication list \
  --registry $ACR_NAME \
  --resource-group $RESOURCE_GROUP \
  --query "[].{Location:location, Status:status.displayStatus}" \
  --output table
```

### Step 4: Configure Webhook for Image Updates

```bash
# Create webhook to notify on image push
az acr webhook create \
  --registry $ACR_NAME \
  --name "ImagePushWebhook" \
  --actions push delete \
  --uri "https://myapp.example.com/webhook/acr" \
  --scope "geo-app:*" \
  --headers "Authorization=Bearer secrettoken123"

# List webhooks
az acr webhook list \
  --registry $ACR_NAME \
  --output table

# Test webhook
az acr webhook ping \
  --registry $ACR_NAME \
  --name "ImagePushWebhook"

# View webhook events
az acr webhook list-events \
  --registry $ACR_NAME \
  --name "ImagePushWebhook" \
  --output table
```

### Step 5: Deploy Multi-Region AKS with Geo-Replicated ACR

```bash
# Create AKS clusters in multiple regions
for REGION in eastus westus westeurope; do
  export CLUSTER_NAME="aks-prod-${REGION}"
  
  echo "Creating AKS cluster in ${REGION}..."
  
  az aks create \
    --resource-group $RESOURCE_GROUP \
    --name $CLUSTER_NAME \
    --location $REGION \
    --node-count 3 \
    --node-vm-size Standard_D4s_v3 \
    --enable-managed-identity \
    --attach-acr $ACR_NAME \
    --network-plugin azure \
    --generate-ssh-keys \
    --no-wait
done

# Wait for all clusters
az aks wait --created --resource-group $RESOURCE_GROUP --name "aks-prod-eastus"
az aks wait --created --resource-group $RESOURCE_GROUP --name "aks-prod-westus"
az aks wait --created --resource-group $RESOURCE_GROUP --name "aks-prod-westeurope"

# Get credentials for all clusters
for REGION in eastus westus westeurope; do
  az aks get-credentials \
    --resource-group $RESOURCE_GROUP \
    --name "aks-prod-${REGION}" \
    --context "aks-prod-${REGION}"
done

# Deploy to all regions
for REGION in eastus westus westeurope; do
  kubectl config use-context "aks-prod-${REGION}"
  
  kubectl create deployment geo-app \
    --image=${ACR_NAME}.azurecr.io/geo-app:v1.0 \
    --replicas=3
  
  kubectl expose deployment geo-app \
    --port=80 \
    --type=LoadBalancer \
    --name=geo-app-service
done
```

---

## Lab 4: Configure Backup and Restore Procedures

### Overview
Implement comprehensive backup and disaster recovery procedures.

### Step 1: Backup ACR Images

```bash
# Export all images from ACR
export BACKUP_DIR="./acr-backup-$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# List all repositories
az acr repository list --name $ACR_NAME -o tsv > $BACKUP_DIR/repositories.txt

# Export each image
while IFS= read -r repo; do
  echo "Backing up repository: $repo"
  
  # Get all tags
  az acr repository show-tags --name $ACR_NAME --repository $repo -o tsv > $BACKUP_DIR/${repo//\//_}_tags.txt
  
  # Pull and save each tag
  while IFS= read -r tag; do
    echo "  Pulling ${repo}:${tag}"
    docker pull ${ACR_NAME}.azurecr.io/${repo}:${tag}
    docker save ${ACR_NAME}.azurecr.io/${repo}:${tag} | gzip > $BACKUP_DIR/${repo//\//_}_${tag}.tar.gz
  done < $BACKUP_DIR/${repo//\//_}_tags.txt
done < $BACKUP_DIR/repositories.txt

echo "Backup completed: $BACKUP_DIR"
ls -lh $BACKUP_DIR
```

### Step 2: Backup AKS Configuration

```bash
# Backup AKS resources
export K8S_BACKUP_DIR="./aks-backup-$(date +%Y%m%d)"
mkdir -p $K8S_BACKUP_DIR

kubectl config use-context "aks-prod-eastus"

# Backup all namespaces
kubectl get namespaces -o yaml > $K8S_BACKUP_DIR/namespaces.yaml

# Backup all resources by type
for RESOURCE in \
  deployments \
  statefulsets \
  daemonsets \
  services \
  ingresses \
  configmaps \
  secrets \
  persistentvolumeclaims \
  persistentvolumes \
  storageclasses \
  serviceaccounts \
  roles \
  rolebindings \
  clusterroles \
  clusterrolebindings \
  networkpolicies \
  horizontalpodautoscalers
do
  echo "Backing up: $RESOURCE"
  kubectl get $RESOURCE --all-namespaces -o yaml > $K8S_BACKUP_DIR/${RESOURCE}.yaml 2>/dev/null || true
done

# Backup using kubectl-slice for better organization
# Install: https://github.com/patrickdappollonio/kubectl-slice
# kubectl get all --all-namespaces -o yaml | kubectl-slice -o $K8S_BACKUP_DIR/sliced/

echo "Kubernetes backup completed: $K8S_BACKUP_DIR"
```

### Step 3: Automated Backup with Azure Backup

```bash
# Create backup vault
export BACKUP_VAULT="vault-containers-backup"

az backup vault create \
  --resource-group $RESOURCE_GROUP \
  --name $BACKUP_VAULT \
  --location $LOCATION

# Note: AKS backup requires Azure Backup extension
# Install AKS Backup extension
az k8s-extension create \
  --name azure-aks-backup \
  --extension-type microsoft.dataprotection.kubernetes \
  --scope cluster \
  --cluster-type managedClusters \
  --cluster-name $AKS_CLUSTER \
  --resource-group $RESOURCE_GROUP \
  --release-train stable \
  --configuration-settings blobContainer=aksbackup storageAccount=backupstorage

# Create backup policy
cat > backup-policy.json <<'EOF'
{
  "properties": {
    "datasourceTypes": ["Microsoft.ContainerService/managedClusters"],
    "objectType": "BackupPolicy",
    "policyRules": [
      {
        "name": "DailyBackup",
        "objectType": "AzureBackupRule",
        "backupParameters": {
          "backupType": "Full",
          "objectType": "AzureBackupParams"
        },
        "trigger": {
          "objectType": "ScheduleBasedTriggerContext",
          "schedule": {
            "repeatingTimeIntervals": ["R/2026-01-29T02:00:00+00:00/P1D"]
          },
          "taggingCriteria": [
            {
              "isDefault": true,
              "taggingPriority": 99,
              "tagInfo": {
                "tagName": "Default"
              }
            }
          ]
        },
        "dataStore": {
          "dataStoreType": "OperationalStore",
          "objectType": "DataStoreInfoBase"
        }
      }
    ],
    "retentionRules": [
      {
        "name": "Default",
        "objectType": "AzureRetentionRule",
        "isDefault": true,
        "lifecycles": [
          {
            "deleteAfter": {
              "objectType": "AbsoluteDeleteOption",
              "duration": "P30D"
            },
            "sourceDataStore": {
              "dataStoreType": "OperationalStore",
              "objectType": "DataStoreInfoBase"
            }
          }
        ]
      }
    ]
  }
}
EOF

echo "Configure AKS Backup in Azure Portal for production use"
```

### Step 4: Create Disaster Recovery Runbook

```bash
# Create disaster recovery documentation
cat > DR-RUNBOOK.md <<'EOF'
# Disaster Recovery Runbook

## Recovery Time Objective (RTO): 4 hours
## Recovery Point Objective (RPO): 24 hours

## Pre-Requisites
- Access to Azure Portal with Owner/Contributor role
- Azure CLI installed and authenticated
- kubectl installed
- Access to backup storage accounts
- Latest backup verification completed

## Scenario 1: Regional Outage

### Detection
1. Check Azure Status: https://status.azure.com
2. Verify monitoring alerts in Azure Monitor
3. Test connectivity to regional resources

### Recovery Steps

#### Step 1: Activate Secondary Region
```bash
# Set variables
export BACKUP_REGION="westus"
export PRIMARY_REGION="eastus"
export AKS_BACKUP_CLUSTER="aks-prod-${BACKUP_REGION}"

# Switch to backup cluster
kubectl config use-context $AKS_BACKUP_CLUSTER

# Verify cluster is healthy
kubectl get nodes
kubectl get pods --all-namespaces
```

#### Step 2: Update Traffic Manager
```bash
# Disable primary endpoint
az network traffic-manager endpoint update \
  --resource-group $RESOURCE_GROUP \
  --profile-name "tm-prod-app" \
  --name "primary-endpoint" \
  --type azureEndpoints \
  --endpoint-status Disabled

# Enable secondary endpoint
az network traffic-manager endpoint update \
  --resource-group $RESOURCE_GROUP \
  --profile-name "tm-prod-app" \
  --name "secondary-endpoint" \
  --type azureEndpoints \
  --endpoint-status Enabled
```

#### Step 3: Verify Application
```bash
# Test application endpoints
curl -I https://app.progresssoftware.com/health

# Check all services are running
kubectl get services --all-namespaces

# Verify database connectivity
# (run application-specific health checks)
```

## Scenario 2: ACR Corruption

### Recovery Steps

#### Step 1: Restore from Backup
```bash
# Find latest backup
BACKUP_DIR=$(ls -td ./acr-backup-* | head -1)

# Restore images
for IMAGE_TAR in $BACKUP_DIR/*.tar.gz; do
  docker load < $IMAGE_TAR
  # Re-tag and push to new/restored ACR
done
```

## Scenario 3: AKS Cluster Failure

### Recovery Steps

#### Step 1: Restore Kubernetes Resources
```bash
# Find latest backup
K8S_BACKUP=$(ls -td ./aks-backup-* | head -1)

# Create new cluster or use standby cluster
az aks get-credentials --resource-group $RESOURCE_GROUP --name $AKS_BACKUP_CLUSTER

# Apply all backed up resources
kubectl apply -f $K8S_BACKUP/namespaces.yaml
kubectl apply -f $K8S_BACKUP/configmaps.yaml
kubectl apply -f $K8S_BACKUP/secrets.yaml
kubectl apply -f $K8S_BACKUP/deployments.yaml
kubectl apply -f $K8S_BACKUP/services.yaml
# Continue for all resource types...
```

## Post-Recovery Checklist
- [ ] All critical services are running
- [ ] Database connections are working
- [ ] Authentication is functioning
- [ ] Monitoring and alerting is operational
- [ ] DNS/Traffic routing is correct
- [ ] Performance metrics are normal
- [ ] Incident postmortem scheduled
- [ ] Documentation updated

## Contact Information
- On-Call Engineer: +1-555-ONCALL
- Azure Support: +1-800-642-7676
- Management Escalation: incidents@progresssoftware.com
EOF

echo "DR Runbook created: DR-RUNBOOK.md"
```

---

## Lab 5: Cost Optimization Techniques

### Overview
Optimize Azure costs while maintaining performance and reliability.

### Step 1: Implement Resource Right-Sizing

```bash
# Analyze current resource usage
kubectl top nodes
kubectl top pods --all-namespaces --sort-by=memory
kubectl top pods --all-namespaces --sort-by=cpu

# Generate resource recommendations
cat > analyze-resources.sh <<'EOF'
#!/bin/bash

echo "=== Resource Usage Analysis ==="
echo ""

echo "Pods with resource requests vs actual usage:"
kubectl get pods --all-namespaces -o json | jq -r '
  .items[] | 
  select(.spec.containers[0].resources.requests != null) |
  {
    namespace: .metadata.namespace,
    name: .metadata.name,
    container: .spec.containers[0].name,
    cpu_request: .spec.containers[0].resources.requests.cpu,
    mem_request: .spec.containers[0].resources.requests.memory,
    cpu_limit: .spec.containers[0].resources.limits.cpu,
    mem_limit: .spec.containers[0].resources.limits.memory
  } |
  "\(.namespace)/\(.name) - CPU: \(.cpu_request) -> \(.cpu_limit), MEM: \(.mem_request) -> \(.mem_limit)"
'

echo ""
echo "Pods without resource limits (should fix):"
kubectl get pods --all-namespaces -o json | jq -r '
  .items[] | 
  select(.spec.containers[0].resources.limits == null) |
  "\(.metadata.namespace)/\(.metadata.name)"
'

echo ""
echo "Over-provisioned pods (using <25% of requests):"
# This requires metrics-server and actual usage data
# Run: kubectl top pods --all-namespaces
EOF

chmod +x analyze-resources.sh
./analyze-resources.sh
```

### Step 2: Use Azure Spot VMs for Non-Critical Workloads

```bash
# Add spot instance node pool to AKS
az aks nodepool add \
  --resource-group $RESOURCE_GROUP \
  --cluster-name $AKS_CLUSTER \
  --name spotnodepool \
  --priority Spot \
  --eviction-policy Delete \
  --spot-max-price -1 \
  --enable-cluster-autoscaler \
  --min-count 1 \
  --max-count 10 \
  --node-count 2 \
  --node-vm-size Standard_D4s_v3 \
  --node-taints kubernetes.azure.com/scalesetpriority=spot:NoSchedule \
  --labels workload=batch priority=low

# Deploy batch jobs to spot instances
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-processing
spec:
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      nodeSelector:
        workload: batch
      tolerations:
      - key: "kubernetes.azure.com/scalesetpriority"
        operator: "Equal"
        value: "spot"
        effect: "NoSchedule"
      containers:
      - name: processor
        image: ${ACR_NAME}.azurecr.io/batch-processor:v1.0
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
      restartPolicy: OnFailure
EOF
```

### Step 3: Enable Container Apps Dynamic Scaling

```bash
# For Azure Container Apps: Use consumption-based scaling
export ACA_ENV="aca-env-prod"
export ACA_APP="aca-cost-optimized"

# Create Container App with aggressive scale-down
az containerapp create \
  --name $ACA_APP \
  --resource-group $RESOURCE_GROUP \
  --environment $ACA_ENV \
  --image ${ACR_NAME}.azurecr.io/myapp:v1.0 \
  --target-port 80 \
  --ingress external \
  --min-replicas 0 \
  --max-replicas 30 \
  --scale-rule-name http-scaling \
  --scale-rule-type http \
  --scale-rule-http-concurrency 50

# Configure scale-to-zero
az containerapp update \
  --name $ACA_APP \
  --resource-group $RESOURCE_GROUP \
  --min-replicas 0 \
  --scale-rule-name http-scaling \
  --scale-rule-http-concurrency 50 \
  --scale-rule-metadata "concurrentRequests=50" "targetQueueLength=10"

# Result: Pay only when app is processing requests
```

### Step 4: Implement ACR Content Trust and Image Cleanup

```bash
# Enable content trust (prevents unauthorized image modifications)
export DOCKER_CONTENT_TRUST=1

# Delete old/unused images
# List images older than 90 days
az acr repository list --name $ACR_NAME -o tsv | while read repo; do
  echo "Checking repository: $repo"
  
  az acr repository show-manifests \
    --name $ACR_NAME \
    --repository $repo \
    --orderby time_desc \
    --query "[?timestamp < '2025-11-01'].{Digest:digest, Tags:tags, Created:timestamp}" \
    -o table
done

# Create retention policy to auto-delete old images
az acr config retention update \
  --registry $ACR_NAME \
  --status enabled \
  --days 90 \
  --type UntaggedManifests

# Delete untagged manifests immediately
az acr repository show-manifests \
  --name $ACR_NAME \
  --repository geo-app \
  --query "[?tags[0]==null].digest" -o tsv | \
  xargs -I% az acr repository delete \
    --name $ACR_NAME \
    --image geo-app@% \
    --yes
```

### Step 5: Use Azure Reserved Instances

```bash
# Calculate potential savings
az consumption reservation recommendation list \
  --resource-group $RESOURCE_GROUP \
  --subscription $(az account show --query id -o tsv) \
  --look-back-period Last30Days

# Purchase reserved VM instances for AKS nodes (via Azure Portal or CLI)
echo "Consider purchasing 1-year or 3-year reservations for:"
echo "  - Standard_D4s_v3 instances for AKS"
echo "  - Estimated savings: 40-60%"
echo "Purchase at: Azure Portal > Reservations > Add"
```

### Step 6: Monitor and Optimize Costs

```bash
# Install Azure Cost Management tools
# Query costs for container resources
az consumption usage list \
  --start-date 2026-01-01 \
  --end-date 2026-01-31 \
  --query "[?contains(instanceName, 'aks') || contains(instanceName, 'acr')].{Name:instanceName, Cost:pretaxCost, Date:usageStart}" \
  -o table

# Create cost alert
az consumption budget create \
  --resource-group $RESOURCE_GROUP \
  --budget-name "container-services-budget" \
  --amount 5000 \
  --time-grain Monthly \
  --start-date $(date +%Y-%m-01) \
  --end-date "2026-12-31" \
  --category Cost \
  --notification-enabled true \
  --notification-operator GreaterThan \
  --notification-threshold 80 \
  --contact-emails ops@progresssoftware.com

echo "Cost monitoring configured"
```

---

## Lab 6: Security Hardening Checklist Implementation

### Overview
Implement comprehensive security measures for production containers.

### Step 1: Enable Azure Policy for AKS

```bash
# Enable Azure Policy add-on
az aks enable-addons \
  --resource-group $RESOURCE_GROUP \
  --name $AKS_CLUSTER \
  --addons azure-policy

# Wait for policy pods
kubectl wait --for=condition=ready pod \
  -n kube-system \
  -l app=azure-policy \
  --timeout=120s

kubectl wait --for=condition=ready pod \
  -n gatekeeper-system \
  -l control-plane=controller-manager \
  --timeout=120s

# Assign built-in policy initiatives
az policy assignment create \
  --name "aks-security-baseline" \
  --display-name "AKS Security Baseline" \
  --scope $(az aks show --resource-group $RESOURCE_GROUP --name $AKS_CLUSTER --query id -o tsv) \
  --policy-set-definition "/providers/Microsoft.Authorization/policySetDefinitions/a8640138-9b0a-4a28-b8cb-1666c838647d"

echo "Azure Policy for AKS enabled"
```

### Step 2: Implement Pod Security Standards

```bash
# Apply Pod Security Standards to namespaces
kubectl label namespace default \
  pod-security.kubernetes.io/enforce=restricted \
  pod-security.kubernetes.io/audit=restricted \
  pod-security.kubernetes.io/warn=restricted

# Create policy to enforce security contexts
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: LimitRange
metadata:
  name: security-limits
  namespace: default
spec:
  limits:
  - type: Container
    defaultRequest:
      cpu: 100m
      memory: 128Mi
    default:
      cpu: 200m
      memory: 256Mi
    max:
      cpu: 2
      memory: 4Gi
    min:
      cpu: 50m
      memory: 64Mi
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: namespace-quota
  namespace: default
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    limits.cpu: "20"
    limits.memory: 40Gi
    persistentvolumeclaims: "10"
    services.loadbalancers: "3"
EOF

# Create NetworkPolicy to restrict traffic
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: default
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-app-traffic
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: secure-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 80
  egress:
  - to:
    - podSelector:
        matchLabels:
          role: database
    ports:
    - protocol: TCP
      port: 5432
  - to:  # Allow DNS
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
EOF
```

### Step 3: Scan Images for Vulnerabilities

```bash
# Enable Microsoft Defender for Containers
az security pricing create \
  --name Containers \
  --tier Standard

# Scan ACR images with Defender
az security assessment create \
  --name "Container registry images should have vulnerability findings resolved" \
  --resource-id $(az acr show --name $ACR_NAME --resource-group $RESOURCE_GROUP --query id -o tsv)

# Use Trivy for local scanning
# Install Trivy: brew install aquasecurity/trivy/trivy

# Scan an image
trivy image ${ACR_NAME}.azurecr.io/geo-app:v1.0

# Scan and fail on HIGH/CRITICAL vulnerabilities
trivy image \
  --severity HIGH,CRITICAL \
  --exit-code 1 \
  ${ACR_NAME}.azurecr.io/geo-app:v1.0

# Integrate into CI/CD
cat > .github/workflows/security-scan.yml <<'EOF'
name: Container Security Scan

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Build image
      run: docker build -t myapp:${{ github.sha }} .
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'myapp:${{ github.sha }}'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH'
    
    - name: Upload results to GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'
EOF
```

### Step 4: Implement RBAC and Least Privilege

```bash
# Create service account with minimal permissions
kubectl create serviceaccount app-service-account

# Create role with specific permissions
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: app-role
  namespace: default
rules:
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-role-binding
  namespace: default
subjects:
- kind: ServiceAccount
  name: app-service-account
  namespace: default
roleRef:
  kind: Role
  name: app-role
  apiGroup: rbac.authorization.k8s.io
EOF

# Use service account in deployment
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app-rbac
spec:
  replicas: 2
  selector:
    matchLabels:
      app: secure-app-rbac
  template:
    metadata:
      labels:
        app: secure-app-rbac
    spec:
      serviceAccountName: app-service-account
      automountServiceAccountToken: true
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: app
        image: ${ACR_NAME}.azurecr.io/secure-app:v1.0
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /app/cache
      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}
EOF
```

### Step 5: Enable Audit Logging

```bash
# Enable AKS diagnostic settings
az monitor diagnostic-settings create \
  --name "aks-audit-logs" \
  --resource $(az aks show --resource-group $RESOURCE_GROUP --name $AKS_CLUSTER --query id -o tsv) \
  --workspace $(az monitor log-analytics workspace show --resource-group $RESOURCE_GROUP --workspace-name $LOG_WORKSPACE --query id -o tsv) \
  --logs '[
    {"category": "kube-apiserver", "enabled": true},
    {"category": "kube-controller-manager", "enabled": true},
    {"category": "kube-scheduler", "enabled": true},
    {"category": "kube-audit", "enabled": true},
    {"category": "kube-audit-admin", "enabled": true},
    {"category": "guard", "enabled": true}
  ]' \
  --metrics '[{"category": "AllMetrics", "enabled": true}]'

# Query audit logs
echo "Query audit logs with:"
echo '
AzureDiagnostics
| where Category == "kube-audit"
| where TimeGenerated > ago(24h)
| where user_s !in ("system:serviceaccount:kube-system:generic-garbage-collector", "system:serviceaccount:kube-system:attachdetach-controller")
| project TimeGenerated, verb_s, objectRef_resource_s, objectRef_name_s, user_s, sourceIPs_s, responseStatus_code_d
| order by TimeGenerated desc
'
```

### Security Hardening Checklist

```markdown
## Container Security Checklist

### Image Security
- [ ] Use minimal base images (alpine, distroless)
- [ ] Scan images for vulnerabilities (Trivy, Defender)
- [ ] Sign images with Docker Content Trust
- [ ] Use specific image tags (not :latest)
- [ ] Remove unnecessary packages and files
- [ ] Run containers as non-root user
- [ ] Use multi-stage builds to reduce attack surface
- [ ] Keep base images updated regularly

### Runtime Security
- [ ] Enable Pod Security Standards (restricted)
- [ ] Implement resource limits and requests
- [ ] Use read-only root filesystems
- [ ] Drop unnecessary Linux capabilities
- [ ] Enable seccomp profiles
- [ ] Use AppArmor or SELinux profiles
- [ ] Disable privilege escalation
- [ ] Implement network policies

### Access Control
- [ ] Enable RBAC with least privilege
- [ ] Use service accounts (not default)
- [ ] Disable automounting of service account tokens when not needed
- [ ] Implement Azure AD integration for AKS
- [ ] Use Azure Key Vault for secrets
- [ ] Rotate credentials regularly
- [ ] Enable audit logging

### Network Security
- [ ] Implement network policies (default deny)
- [ ] Use Azure Private Link for ACR
- [ ] Enable AKS private cluster (if applicable)
- [ ] Implement ingress/egress filtering
- [ ] Use Azure Firewall for outbound traffic
- [ ] Enable DDoS protection
- [ ] Use TLS/SSL for all communications

### Compliance & Governance
- [ ] Enable Azure Policy for AKS
- [ ] Implement logging and monitoring
- [ ] Configure log retention policies
- [ ] Enable Microsoft Defender for Containers
- [ ] Implement backup and disaster recovery
- [ ] Document security procedures
- [ ] Regular security audits and penetration testing
- [ ] Compliance with industry standards (PCI-DSS, HIPAA, etc.)
```

---

## Multi-Region Deployment Strategy

### Azure Traffic Manager Configuration

```bash
# Create Traffic Manager profile
export TM_PROFILE="tm-prod-app"
export TM_DNS="prodapp-tm"

az network traffic-manager profile create \
  --name $TM_PROFILE \
  --resource-group $RESOURCE_GROUP \
  --routing-method Performance \
  --unique-dns-name $TM_DNS \
  --ttl 30 \
  --protocol HTTP \
  --port 80 \
  --path "/health"

# Add endpoints for each region
for REGION in eastus westus westeurope; do
  export CLUSTER_NAME="aks-prod-${REGION}"
  
  # Get LoadBalancer IP
  kubectl config use-context $CLUSTER_NAME
  export LB_IP=$(kubectl get service geo-app-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
  
  # Create public IP resource (if not already existing)
  az network public-ip create \
    --resource-group $RESOURCE_GROUP \
    --name "pip-app-${REGION}" \
    --location $REGION \
    --allocation-method Static \
    --sku Standard \
    --ip-address $LB_IP || true
  
  export PIP_ID=$(az network public-ip show \
    --resource-group $RESOURCE_GROUP \
    --name "pip-app-${REGION}" \
    --query id -o tsv)
  
  # Add Traffic Manager endpoint
  az network traffic-manager endpoint create \
    --name "${REGION}-endpoint" \
    --profile-name $TM_PROFILE \
    --resource-group $RESOURCE_GROUP \
    --type azureEndpoints \
    --target-resource-id $PIP_ID \
    --endpoint-status Enabled \
    --priority $(case $REGION in eastus) echo 1;; westus) echo 2;; *) echo 3;; esac)
done

# Get Traffic Manager DNS name
az network traffic-manager profile show \
  --name $TM_PROFILE \
  --resource-group $RESOURCE_GROUP \
  --query dnsConfig.fqdn -o tsv

# Expected: prodapp-tm.trafficmanager.net
```

---

## Summary

In this lab, you learned how to:
- ✅ Secure containerized applications with Azure Key Vault
- ✅ Configure geo-replication for high availability
- ✅ Implement comprehensive backup and disaster recovery
- ✅ Optimize costs while maintaining performance
- ✅ Apply security hardening best practices
- ✅ Design multi-region deployments with Traffic Manager
- ✅ Implement production-grade governance and compliance

---

## Production Deployment Best Practices Summary

### 1. **Security First**
- Use Azure Key Vault for all secrets
- Implement least privilege access (RBAC)
- Scan images for vulnerabilities
- Enable audit logging
- Use network policies

### 2. **High Availability**
- Deploy across multiple regions
- Use geo-replicated ACR
- Implement health checks
- Configure auto-scaling
- Use Azure Traffic Manager

### 3. **Disaster Recovery**
- Regular backups (automated)
- Documented runbooks
- Tested recovery procedures
- Multi-region failover
- RPO/RTO defined and tested

### 4. **Monitoring & Observability**
- Comprehensive logging
- Real-time metrics
- Proactive alerting
- Distributed tracing
- Cost monitoring

### 5. **Cost Optimization**
- Right-size resources
- Use spot instances for non-critical workloads
- Enable autoscaling
- Clean up unused resources
- Leverage reserved instances

### 6. **Governance**
- Azure Policy enforcement
- Compliance auditing
- Change management
- Documentation
- Regular reviews

---

## Additional Resources

- [Azure Well-Architected Framework](https://docs.microsoft.com/azure/architecture/framework/)
- [AKS Best Practices](https://docs.microsoft.com/azure/aks/best-practices)
- [Azure Security Benchmark](https://docs.microsoft.com/security/benchmark/azure/)
- [Container Security Best Practices](https://docs.microsoft.com/azure/container-instances/container-instances-image-security)
- [Azure Key Vault Best Practices](https://docs.microsoft.com/azure/key-vault/general/best-practices)

---

## Congratulations!

You have completed Module 5 and the entire **Progress Software Container Training Series**! You now have comprehensive knowledge of:

✅ **Module 1**: Container fundamentals and Docker basics  
✅ **Module 2**: .NET containerization and Dockerfiles  
✅ **Module 3**: Azure Container Registry provisioning and management  
✅ **Module 4**: Deploying to Azure container services (ACI, ACA, AKS, App Service)  
✅ **Module 5**: Production monitoring, troubleshooting, and best practices  

You are now ready to deploy and manage production-grade containerized .NET applications on Azure!

---

**Progress Software - Delivering Enterprise-Grade Container Solutions**
